name: Data Pipeline

on:
  workflow_dispatch:
    inputs:
      region:
        description: "AWS Region"
        required: true
        default: "ap-southeast-2"
      SourceBucketName:
        description: "S3 Source Bucket Name"
        default: "source-bucket-chien"
        required: true
      DataBucketName:
        description: "S3 Data Bucket Name"
        default: "data-bucket-chien"

jobs:
  pipeline:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v2

      - name: Configure AWS credentials
        id: creds-pipeline
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ github.event.inputs.region }}

      - name: Run crawler script
        run: |
          bash pipeline/crawler.sh
        env:
          SourceBucketName: ${{ github.event.inputs.SourceBucketName }}
          CrawlerName: source-csv-crawler

      - name: Install jq
        run: sudo apt-get update && sudo apt-get install -y jq

      - name: Install dbt and dbt-redshift
        run: |
          python3 -m venv venv
          source venv/bin/activate
          pip install --upgrade pip
          pip install dbt-core dbt-redshift
          echo "âœ… dbt and dbt-redshift installed."

      - name: Setup dbt profile using Secrets Manager
        run: pipeline/dbt-profiles.sh
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: ${{ github.event.inputs.region }}

      - name: Run dbt
        run: |
          cd dbt_project
          dbt run --profiles-dir ~/.dbt
